{"nbformat": 4, "nbformat_minor": 5, "metadata": {"kernelspec": {"name": "python3", "display_name": "Python 3"}, "language_info": {"name": "python", "pygments_lexer": "ipython3"}}, "cells": [{"cell_type": "markdown", "metadata": {}, "source": "# Week 1 \u2014 PCA via SVD (Day-by-Day: Read / Watch / Do)"}, {"cell_type": "code", "metadata": {}, "source": "import numpy as np\nimport matplotlib.pyplot as plt\nnp.set_printoptions(precision=4, suppress=True)\n%matplotlib inline\nrng = np.random.default_rng(0)", "execution_count": null, "outputs": []}, {"cell_type": "markdown", "metadata": {}, "source": "## Day 1 \u2014 Linear algebra quick pass"}, {"cell_type": "code", "metadata": {}, "source": "# Norms & triangle inequality\nX = rng.normal(size=(3, 4))\nfor i, x in enumerate(X):\n    l1, l2, linf = np.sum(np.abs(x)), np.linalg.norm(x), np.max(np.abs(x))\n    print(f\"v{i}: ||.||1={l1:.3f}, ||.||2={l2:.3f}, ||.||inf={linf:.3f}\")\nx, y = X[0], X[1]\nprint(\"triangle inequality:\", np.linalg.norm(x+y) <= np.linalg.norm(x)+np.linalg.norm(y))", "execution_count": null, "outputs": []}, {"cell_type": "code", "metadata": {}, "source": "# Projection onto a line P = (u u^T) / (u^T u)\nu = rng.normal(size=(4,))\nP = np.outer(u, u) / (u @ u)\nprint(\"symmetric:\", np.allclose(P, P.T))\nprint(\"idempotent (P^2=P):\", np.allclose(P @ P, P))\n\nx = rng.normal(size=(4,))\nx_proj = P @ x\north = x - (x @ u)/(u @ u) * u\nprint(\"x_proj \u27c2 orthogonal part:\", np.isclose(x_proj @ orth, 0, atol=1e-8))", "execution_count": null, "outputs": []}, {"cell_type": "code", "metadata": {}, "source": "# (Optional) Gram\u2013Schmidt\ndef gram_schmidt(A, eps=1e-12):\n    Q = []\n    for v in A.T:\n        w = v.astype(float)\n        for q in Q:\n            w -= q * (q @ w)\n        n = np.linalg.norm(w)\n        if n > eps:\n            Q.append(w/n)\n    return np.stack(Q, axis=1)\n\nA = rng.normal(size=(4, 2))\nQ = gram_schmidt(A)\nprint(\"Q^T Q \u2248 I:\", np.allclose(Q.T @ Q, np.eye(Q.shape[1])))", "execution_count": null, "outputs": []}, {"cell_type": "markdown", "metadata": {}, "source": "## Day 2 \u2014 SVD \u2194 PCA link"}, {"cell_type": "code", "metadata": {}, "source": "# EVR from SVD\nX = rng.normal(size=(6, 3))\nmu = X.mean(axis=0, keepdims=True)\nXc = X - mu\nU, s, Vt = np.linalg.svd(Xc, full_matrices=False)\nV = Vt.T\n\nevr = (s**2) / (s**2).sum()\nprint(\"\u03c3:\", s)\nprint(\"EVR:\", evr, \"sum:\", evr.sum())", "execution_count": null, "outputs": []}, {"cell_type": "code", "metadata": {}, "source": "# Covariance eigenvalues \u2259 \u03a3^2/(n-1)\nCov = (Xc.T @ Xc) / (Xc.shape[0] - 1)\nw, _ = np.linalg.eigh(Cov)\nprint(\"eigvals(Cov) desc:\", w[::-1])\nprint(\"\u03a3^2/(n-1):       \", (s**2)/(Xc.shape[0]-1))", "execution_count": null, "outputs": []}, {"cell_type": "markdown", "metadata": {}, "source": "## Day 3 \u2014 Implement PCA via SVD"}, {"cell_type": "code", "metadata": {}, "source": "# Reusable helpers\ndef pca_fit_svd(X):\n    X = np.asarray(X)\n    mu = X.mean(axis=0, keepdims=True)\n    Xc = X - mu\n    U, s, Vt = np.linalg.svd(Xc, full_matrices=False)\n    V = Vt.T\n    evr = (s**2) / (s**2).sum()\n    return mu, V, s, evr\n\ndef pca_transform(X, mu, V, k):\n    return (X - mu) @ V[:, :k]\n\ndef pca_inverse_transform(Z, mu, V, k):\n    return Z @ V[:, :k].T + mu", "execution_count": null, "outputs": []}, {"cell_type": "code", "metadata": {}, "source": "# 2D demo + rank-1 reconstruction\nN = 500\nstds = np.array([3.0, 0.7])\nX2 = rng.normal(size=(N,2)) * stds\ntheta = np.deg2rad(35)\nR = np.array([[np.cos(theta), -np.sin(theta)],\n              [np.sin(theta),  np.cos(theta)]])\nX2 = X2 @ R.T\n\nmu2, V2, s2, evr2 = pca_fit_svd(X2)\nZ1 = pca_transform(X2, mu2, V2, 1)\nX2_hat1 = pca_inverse_transform(Z1, mu2, V2, 1)\nprint(\"EVR:\", evr2, \"sum:\", evr2.sum())\nprint(\"MSE k=1:\", np.mean((X2 - X2_hat1)**2))\n\nplt.figure(figsize=(5,5))\nplt.scatter(X2[:,0], X2[:,1], s=8, alpha=0.35, label='data')\nplt.scatter(X2_hat1[:,0], X2_hat1[:,1], s=8, alpha=0.35, label='recon (k=1)')\nplt.legend(); plt.axis('equal'); plt.title('Rank-1 PCA reconstruction'); plt.show()", "execution_count": null, "outputs": []}, {"cell_type": "markdown", "metadata": {}, "source": "## Day 4 \u2014 Evaluation & choosing k"}, {"cell_type": "code", "metadata": {}, "source": "# Helper + 3D example\ndef choose_k_by_threshold(evr, threshold=0.95):\n    c = np.cumsum(evr)\n    return int(np.searchsorted(c, threshold) + 1), c\n\nA = np.array([[1.0, 0.8, 0.6],\n              [0.8, 2.0, 1.1],\n              [0.6, 1.1, 1.5]])\nL = np.linalg.cholesky(A)\nX3 = rng.normal(size=(600,3)) @ L.T\n\nmu3, V3, s3, evr3 = pca_fit_svd(X3)\nk95, cum = choose_k_by_threshold(evr3, 0.95)\nprint(\"k for 95% EV:\", k95)", "execution_count": null, "outputs": []}, {"cell_type": "code", "metadata": {}, "source": "# Cumulative EV plot\nplt.figure(figsize=(5,4))\nplt.plot(np.arange(1, len(evr3)+1), cum, marker='o')\nplt.axhline(0.95, linestyle='--')\nplt.xlabel('k'); plt.ylabel('cumulative EV'); plt.title('Cumulative explained variance')\nplt.show()", "execution_count": null, "outputs": []}, {"cell_type": "code", "metadata": {}, "source": "# Reconstruction error vs k\nmses = []\nfor k in range(1, X3.shape[1]+1):\n    Zk = pca_transform(X3, mu3, V3, k)\n    Xhat = pca_inverse_transform(Zk, mu3, V3, k)\n    mses.append(np.mean((X3 - Xhat)**2))\n\nplt.figure(figsize=(5,4))\nplt.plot(range(1, len(mses)+1), mses, marker='o')\nplt.xlabel('k'); plt.ylabel('MSE'); plt.title('Reconstruction error vs k')\nplt.show()", "execution_count": null, "outputs": []}, {"cell_type": "markdown", "metadata": {}, "source": "## Day 5 \u2014 Whitening & eigen route"}, {"cell_type": "code", "metadata": {}, "source": "# Whitening check\ndef pca_whiten(Z, s, k, eps=1e-6):\n    return Z / (s[:k] + eps)\n\nk = 2\nZ = pca_transform(X3, mu3, V3, k)\nZw = pca_whiten(Z, s3, k)\nprint(\"Cov(Z):\\n\", np.cov(Z.T))\nprint(\"Cov(Z whitened):\\n\", np.cov(Zw.T))", "execution_count": null, "outputs": []}, {"cell_type": "code", "metadata": {}, "source": "# Covariance eigen-decomposition PCA (compare to SVD)\ndef pca_fit_eig(X):\n    X = np.asarray(X)\n    mu = X.mean(axis=0, keepdims=True)\n    Xc = X - mu\n    C = (Xc.T @ Xc) / (X.shape[0] - 1)\n    w, V = np.linalg.eigh(C)           # ascending\n    idx = np.argsort(w)[::-1]          # descending\n    w, V = w[idx], V[:, idx]\n    s = np.sqrt(w * (X.shape[0] - 1))  # singular values\n    evr = w / w.sum()\n    return mu, V, s, evr\n\nmu_e, V_e, s_e, evr_e = pca_fit_eig(X3)\nprint(\"EVR match:\", np.allclose(evr3, evr_e))\nprint(\"Principal directions align (abs diag V^T V_e):\", np.abs(np.diag(V3.T @ V_e)))", "execution_count": null, "outputs": []}]}